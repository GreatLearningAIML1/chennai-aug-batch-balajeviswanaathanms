{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_Internal_Lab_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "cell_type": "markdown",
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9]."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YUB1uDW_8XIy"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Import necessary libraries for the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rsj4t5HTaEJE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IXrn3heBaEJa"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Import MNIST data and create 2 datasets with one dataset having digits from 0 to 4 and other from 5 to 9 "
      ]
    },
    {
      "metadata": {
        "id": "8DPQi9fj2xTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9SOsLHYNc2bW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset with digits from 0 to 4\n",
        "x_train_1 = x_train[y_train < 5]\n",
        "y_train_1 = y_train[y_train < 5]\n",
        "x_test_1 = x_test[y_test < 5]\n",
        "y_test_1 = y_test[y_test < 5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmYht_xac7L4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dataset with digits from 5 to 9\n",
        "x_train_2 = x_train[y_train >= 5]\n",
        "y_train_2 = y_train[y_train >= 5] - 5\n",
        "x_test_2 = x_test[y_test >= 5]\n",
        "y_test_2 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "9qU14lYL9A5g"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Print x_train, y_train, x_test and y_test for both the datasets"
      ]
    },
    {
      "metadata": {
        "id": "aldXNpKeefD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "aeaea490-808a-4b78-8b53-153b1071c2a7"
      },
      "cell_type": "code",
      "source": [
        "print(x_train_1.shape)\n",
        "print(y_train_1.shape)\n",
        "print(x_test_1.shape)\n",
        "print(y_test_1.shape)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30596, 28, 28)\n",
            "(30596,)\n",
            "(5139, 28, 28)\n",
            "(5139,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uooXDtQDel1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cbc6380d-5512-410e-a844-92bb664077c1"
      },
      "cell_type": "code",
      "source": [
        "print(x_train_2.shape)\n",
        "print(y_train_2.shape)\n",
        "print(x_test_2.shape)\n",
        "print(y_test_2.shape)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(29404, 28, 28)\n",
            "(29404,)\n",
            "(4861, 28, 28)\n",
            "(4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z9OrszhJ0SgJ",
        "outputId": "ffd7c7b1-880d-4efb-c239-24007b89a30f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1222
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(x_train_1[1000])\n",
        "\n",
        "plt.imshow(x_train_1[1000])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 128 128 255 255 255 255 255 255 128\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  64 255 255 255 255 255 255 255 255 255\n",
            "  128   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  64 255 255 255 191  64   0   0 128 191 255\n",
            "  255  64   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 191 255 255  64   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 191 255 128   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 128   0   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 128 128 191 128 255 255\n",
            "  255 128   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 191 255 255 255 255 255 255 255\n",
            "  255  64   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  64 255 255 255 255 255 255 255 255 255\n",
            "  255 255 128 128 128   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 128 255 255 255   0   0 191 255 255 255\n",
            "  255 255 255 255 255   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 255 255  64   0  64 255 255 255 255\n",
            "  191 255 255 255 191   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 191 255 128   0   0 191 255 255 255  64\n",
            "    0   0  64 128  64   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255 191 128 255 255 255 255 128   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 255 255 255 255 255 255 255  64   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 128 255 255 255 255 191 128   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 128 191 255 128  64   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fec043497d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngy4VYNClAgy6VIBBlwow6FIBBl0q4P8BlZSNY+dwUP0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sJswV4xk9jQS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1222
        },
        "outputId": "eff4aa8f-d1fa-4e55-8641-c8d2bb0ed85c"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(x_test_1[1000])\n",
        "\n",
        "plt.imshow(x_test_1[1000])"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  18 105 227 253 253 253 193 113   4   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  57 199 253 252 252 252 252 253 252 186  28\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   8 128 246 252 250 160  21  21  21 144 238 252 212\n",
            "   21   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 197 252 252 199  70   0   0   0   0   0  28 142 252\n",
            "  182   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 148 252 252 226  24   0   0   0   0   0   0   0  13 217\n",
            "  252  89   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  62 150  97   0   0   0   0   0   0   0   0   0   0  27\n",
            "  229 237  37   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  211 253 142   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  158 253 168   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  106 253 168   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  106 253 203   9   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  107 255 253  21   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  141 253 189   5   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  75 127 180 232 232 233 153  74  22\n",
            "  215 253 159   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 218 252 252 252 252 253 252 252 252\n",
            "  252 253 133   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 177 253 252 244 147 147 165 252 252 252\n",
            "  252 253 168   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 212 254 218  51  43  43 105 227 253 253\n",
            "  253 255 218  30   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 211 253 252 252 252 252 253 252 252 231\n",
            "  168 253 252 161   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 193 253 252 252 252 252 253 201 118  16\n",
            "    0 100 247 251 135   4   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  84  84  84  84  84  84  21   0   0\n",
            "    0   0 120 252 252  42   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  50 200 226  24   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fec044ac850>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npQwYdCkD/wen4wZs8SqKhwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cB9BPFzr9oDF"
      },
      "cell_type": "markdown",
      "source": [
        "## ** 4. Let us take only the dataset (x_train, y_train, x_test, y_test) for Integers 0 to 4 in MNIST **\n",
        "## Reshape x_train and x_test to a 4 Dimensional array (channel = 1) to pass it into a Conv2D layer"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FlQRPfFzaEJx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reshape 0 to 4 dataset\n",
        "x_train_11 = x_train_1.reshape(30596, 28, 28, 1).astype('float32')\n",
        "x_test_11 = x_test_1.reshape(5139, 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YSNZ_ft6gBq_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKxyBGR3gQJb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test_11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SkaENNXzlxwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reshape 5 to 9 dataset\n",
        "x_train_21 = x_train_2.reshape(29404, 28, 28, 1).astype('float32')\n",
        "x_test_21 = x_test_2.reshape(4861, 28, 28, 1).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9R-zybP2mEyi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "49pQgt99mIze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_test_21"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jLQr-b3F-hw8"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Normalize x_train and x_test by dividing it by 255"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PlEZIAG5-g2I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a36e09b4-cd8d-449e-acb5-40dd7ab985d0"
      },
      "cell_type": "code",
      "source": [
        "#Normalizing the input 0 to 4\n",
        "x_train_11 /= 255\n",
        "x_test_11 /= 255\n",
        "print('x_train_11 shape:', x_train_11.shape)\n",
        "print(x_train_11.shape[0], 'train samples')\n",
        "print(x_test_11.shape[0], 'test samples')\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x_train_11 shape:', (30596, 28, 28, 1))\n",
            "(30596, 'train samples')\n",
            "(5139, 'test samples')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "STd4BGkXmM-w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ba2fee9c-a9a3-4d32-d29b-926e38030998"
      },
      "cell_type": "code",
      "source": [
        "#Normalizing the input 5 to 9\n",
        "x_train_21 /= 255\n",
        "x_test_21 /= 255\n",
        "print('x_train_21 shape:', x_train_21.shape)\n",
        "print(x_train_21.shape[0], 'train samples')\n",
        "print(x_test_21.shape[0], 'test samples')"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('x_train_21 shape:', (29404, 28, 28, 1))\n",
            "(29404, 'train samples')\n",
            "(4861, 'test samples')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pytVBaw4-vMi"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V48xiua4-uUi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_set1 = keras.utils.to_categorical(y_train_1, 5)\n",
        "y_test_set2 = keras.utils.to_categorical(y_test_1, 5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JusO9fWklXo6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert class vectors to binary class matrices\n",
        "y_train_set2 = keras.utils.to_categorical(y_train_2, 5)\n",
        "y_test_set2 = keras.utils.to_categorical(y_test_2, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "elPkI44g_C2b"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Build a sequential model with 2 Convolutional layers with 32 kernels of size (3,3) followed by a Max pooling layer of size (2,2) followed by a drop out layer to be trained for classification of digits 0-4  "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MU09mm9F89gO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28, 28, 1),name='conv_1'))\n",
        "\n",
        "#Add a Convolutional Layer with 64 filters of size 3X3 and activation function as 'ReLU' \n",
        "model.add(Conv2D(64, (3, 3), activation='relu',name='conv_2'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25,name='drop_1'))\n",
        "\n",
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(128, activation='relu',name='dense_1'))\n",
        "\n",
        "\n",
        "#Add Fully Connected Layer with 5 units and activation function as 'softmax'\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sJQaycRO_3Au"
      },
      "cell_type": "markdown",
      "source": [
        "## 8. Post that flatten the data and add 2 Dense layers with 128 neurons and neurons = output classes with activation = 'relu' and 'softmax' respectively. Add dropout layer inbetween if necessary  "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vOZeRbK7t9AT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "my1P09bxAv8H"
      },
      "cell_type": "markdown",
      "source": [
        "## 9. Print the training and test accuracy"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yf7F8Gdutbf0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "z78o3WIjaEJ3"
      },
      "cell_type": "markdown",
      "source": [
        "## 10. Make only the dense layers to be trainable and convolutional layers to be non-trainable"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "brN7VZHFaEJ4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4opnW7o0BJ8P"
      },
      "cell_type": "markdown",
      "source": [
        "## 11. Use the model trained on 0 to 4 digit classification and train it on the dataset which has digits 5 to 9  (Using Transfer learning keeping only the dense layers to be trainable)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lCFcYHTm6-cE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DITyAt3t7Tto",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SoDozqghCJZ4"
      },
      "cell_type": "markdown",
      "source": [
        "## 12. Print the accuracy for classification of digits 5 to 9"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9fCxgb5s49Cj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LRWizZIpCUKg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FU-HwvIdH0M-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sentiment analysis <br> \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "metadata": {
        "id": "nAQDiZHRH0M_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 13. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
      ]
    },
    {
      "metadata": {
        "id": "3eXGIe-SH0NA",
        "colab_type": "code",
        "outputId": "01c80271-c2e0-460c-de3d-02385c6ce864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CWeWe1eJH0NF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPJvTjefH0NI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 14. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."
      ]
    },
    {
      "metadata": {
        "id": "5iec5s9gH0NI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    try:\n",
        "        return text.decode('ascii')\n",
        "    except Exception as e:\n",
        "        return \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EQSmqA-vH0NT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['text'] = [preprocess(text) for text in data.tweet_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7kX-WoJDH0NV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OGWB3P2WH0NY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 15. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
      ]
    },
    {
      "metadata": {
        "id": "bdgA_8N2H0NY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Jlu-reIH0Na",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SotCRvkDH0Nf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 16. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
        "\n",
        "#### Use `vect` as the variable name for initialising CountVectorizer."
      ]
    },
    {
      "metadata": {
        "id": "YcbkY4sgH0Ng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KyXtZGr-H0Nl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z4LUM-XPH0Nn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aIdZYxJtH0Nq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5pxd5fSHH0Nt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 17. Find number of different words in vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "p1DQ2LdNH0Nu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwtgjTBeH0Ny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tip: To see all available functions for an Object use dir"
      ]
    },
    {
      "metadata": {
        "id": "2n_iCcTNH0N0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShA6D8jKH0N5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 18. Find out how many Positive and Negative emotions are there.\n",
        "\n",
        "Hint: Use value_counts on that column"
      ]
    },
    {
      "metadata": {
        "id": "q7LAl5pzH0N6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUvgj0FoH0N9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 19. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n",
        "\n",
        "Hint: use map on that column and give labels"
      ]
    },
    {
      "metadata": {
        "id": "YftKwFv7H0N9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3YErwYLCH0N_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 20. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
      ]
    },
    {
      "metadata": {
        "id": "lNkwrGgEH0OA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5nlCuaaH0OD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 21. **Predicting the sentiment:**\n",
        "\n",
        "\n",
        "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
      ]
    },
    {
      "metadata": {
        "id": "2AbVYssaH0OE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktXrLhmOH0Of",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clv2X0kKH0Ok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K86LRMfdH0Ou",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sw-0B33tH0Ox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 22. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
      ]
    },
    {
      "metadata": {
        "id": "okCTOs1TH0Oy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tokenize_test(vect):\n",
        "    x_train_dtm = vect.fit_transform(x_train)\n",
        "    print('Features: ', x_train_dtm.shape[1])\n",
        "    x_test_dtm = vect.transform(x_test)\n",
        "    nb = MultinomialNB()\n",
        "    nb.fit(x_train_dtm, y_train)\n",
        "    y_pred_class = nb.predict(x_test_dtm)\n",
        "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JxZ8jfPEH0O0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "kdCyAN_IH0O0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axepytmgH0O4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "HToGkq7vH0O4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iOIlJRxoH0O7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "6fUhff-oH0O8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S2KZNWVkH0PA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "3v9XD082H0PB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "We3JK_SRH0PO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "fUHrfDCyH0PP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3H4k_lVZH0PS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}