{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "QGIsF1ADyJ58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "metadata": {
        "id": "E-n6tVFayGBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "metadata": {
        "id": "EHTytReaj51L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tR6xD9tyjsBT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "247a36af-65ee-4ea4-a55d-466930b71700"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cq8ejXHJyGYq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "metadata": {
        "id": "uWYbxnBayFUP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(trainX, trainY),(testX, testY) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cW4cMNgekVHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainXset1 = []\n",
        "trainYset1 = []\n",
        "trainXset2 = []\n",
        "trainYset2 = []\n",
        "for i in range(len(trainY)):\n",
        "  if ((trainY[i] == 1) or (trainY[i] == 2) or (trainY[i] == 3) or (trainY[i] == 4) or (trainY[i] == 0)):\n",
        "    trainYset1.append(trainY[i])\n",
        "    trainXset1.append(trainX[i])\n",
        "  else:\n",
        "    trainYset2.append(trainY[i])\n",
        "    trainXset2.append(trainX[i])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "57iAVG9bkde8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testXset1 = []\n",
        "testYset1 = []\n",
        "testXset2 = []\n",
        "testYset2 = []\n",
        "for i in range(len(testY)):\n",
        "  if ((testY[i] == 1) or (testY[i] == 2) or (testY[i] == 3) or (testY[i] == 4) or (testY[i] == 0)):\n",
        "    testYset1.append(testY[i])\n",
        "    testXset1.append(testX[i])\n",
        "  else:\n",
        "    testYset2.append(testY[i])\n",
        "    testXset2.append(testX[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HOq2lUNGkdV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5542cfde-89c6-4b3f-f95e-8929cc8c65c3"
      },
      "cell_type": "code",
      "source": [
        "print('length of X trainset 0-4 :', len(trainXset1))\n",
        "print('length of Y trainset 0-4 :', len(trainYset1))\n",
        "print('length of X testset 0-4 :', len(testXset1))\n",
        "print('length of Y testset 0-4 :', len(testYset1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of X trainset 0-4 : 25000\n",
            "length of Y trainset 0-4 : 25000\n",
            "length of X testset 0-4 : 5000\n",
            "length of Y testset 0-4 : 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WPBDoRj5iUWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b7944b09-f9b6-4279-ee94-3151abf960d5"
      },
      "cell_type": "code",
      "source": [
        "print('length of X trainset 5-9 :', len(trainXset2))\n",
        "print('length of Y trainset 5-9 :', len(trainYset2))\n",
        "print('length of X testset 5-9 :', len(testXset2))\n",
        "print('length of Y testset 5-9 :', len(testYset2))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of X trainset 5-9 : 25000\n",
            "length of Y trainset 5-9 : 25000\n",
            "length of X testset 5-9 : 5000\n",
            "length of Y testset 5-9 : 5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xtCKmQh4yXhT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "metadata": {
        "id": "uN5O2kJ3yYa6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainXset1 = np.array(trainXset1)\n",
        "trainYset1 = np.array(trainYset1)\n",
        "testXset1  = np.array(testXset1)\n",
        "testYset1  = np.array(testYset1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kbsVkkXiz8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainXset2 = np.array(trainXset2)\n",
        "trainYset2 = np.array(trainYset2)\n",
        "testXset2  = np.array(testXset2)\n",
        "testYset2  = np.array(testYset2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tWVHEL0Hi2WK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('train shape:', trainXset1.shape)\n",
        "print('test  shape:', testXset1.shape)\n",
        "x1, y1, z1 = trainXset1.shape\n",
        "x2, y2, z2 = testXset1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4ODqMwc7i54W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainXset1 = np.reshape(trainXset1, (x1,y1,z1,1))\n",
        "testXset1  = np.reshape(testXset1, (x2,y2,z2,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IGvbFDoRi9E0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "de5bc37b-edcf-434a-82da-8bd7e2f173eb"
      },
      "cell_type": "code",
      "source": [
        "print('train shape:', trainXset1.shape)\n",
        "print('test  shape:', testXset1.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (25000, 32, 32, 3)\n",
            "test  shape: (5000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "elP7JPiYjArA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainXset1 = trainXset1/255\n",
        "testXset1  = testXset1/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C4cYx7yhjEhY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainYset1 = tf.keras.utils.to_categorical(trainYset1, num_classes=5)\n",
        "testYset1 = tf.keras.utils.to_categorical(testYset1, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cuOiKWfeybAl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "metadata": {
        "id": "5HzxNbiiyoBD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = (y1, z1, 1)\n",
        "model = Sequential()\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape,name='conv_1'))\n",
        "\n",
        "#Add a Convolutional Layer with 32 filters of size 3X3\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',input_shape=input_shape,name='conv_2'))\n",
        "\n",
        "#Add a MaxPooling Layer of size 2X2 \n",
        "model.add(MaxPooling2D(pool_size=(2, 2),name='max_1'))\n",
        "\n",
        "#Apply Dropout with 0.25 probability \n",
        "model.add(Dropout(0.25,name='drop_1'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHM_x-VZk3cJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Flatten the layer\n",
        "model.add(Flatten())\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(128, activation='relu',name='dense_1'))\n",
        "\n",
        "#Add Fully Connected Layer with 128 units and activation function as 'ReLU'\n",
        "model.add(Dense(5, activation='softmax',name='dense_2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9sxdIXAk8i9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "2\n",
        "#Set the loss function and optimizer for the model training\n",
        "3\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "4\n",
        "              optimizer='adam',\n",
        "5\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8vS6hfK3lEVd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainXset1, trainYset1,\n",
        "          batch_size=32,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          validation_data=(testXset1, testYset1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woTfNst_ynRG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "metadata": {
        "id": "o_VCDB3Byb1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-uUPqWpyeyX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "metadata": {
        "id": "szHjJgDvyfCt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zDuRecXzEtr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "metadata": {
        "id": "xMPlEJhHzb6P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Load the dataset from sklearn.datasets"
      ]
    },
    {
      "metadata": {
        "id": "Fe-B59u3zHNb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRrMemVQzbHU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-sZX0UbJzmg5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 7. Training data"
      ]
    },
    {
      "metadata": {
        "id": "CITr_5aXziJ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xcESc5QXzr6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 8. Test data"
      ]
    },
    {
      "metadata": {
        "id": "ysInblUMzpvl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DriL2yZ50DQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "metadata": {
        "id": "vlUuai99z1hX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEKzaDfSz5E-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clBMKHzC0_N1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twenty_train.data[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hTz4EaN_1WGc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "metadata": {
        "id": "H5G477f81C0Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tp_fDINJ1t4L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "metadata": {
        "id": "THlN2b5d1yQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}