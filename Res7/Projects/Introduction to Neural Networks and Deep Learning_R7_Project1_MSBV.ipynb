{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introduction to Neural Networks and Deep Learning_R7_Project1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "D2lvVYSmP7Fx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ear Participant,\n",
        "\n",
        "We welcome you all to the Project - 1.zipView in a new window case-based of this course. This project has 2 case studies. The first case study (described below - 30 points) covers concepts taught in Part 1 (first 8 hours of Neural networks basics).\n",
        "\n",
        " 1st case study - Project 1:\n",
        "\n",
        " The case study is from a dataset from Kaggle. \n",
        "\n",
        "Link to the Kaggle project site:\n",
        "\n",
        "https://www.kaggle.com/c/plant-seedlings-classification (Links to an external site.)Links to an external site.\n",
        "\n",
        " The dataset has to be downloaded from the above Kaggle web site.\n",
        "\n",
        " Can you differentiate a weed from a crop seedling?\n",
        "\n",
        "The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
        "\n",
        "The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of approximately 960 unique plants belonging to 12 species at several growth stages.\n",
        "\n",
        " \n",
        "\n",
        "The points distribution for this case is as follows:\n",
        "\n",
        "Read the images and generate the train and test dataset (5 points)\n",
        "2. Divide the data set into Train and validation data sets\n",
        "3. Initialize & build the model (10 points)\n",
        "4. Optimize the model (5 points)\n",
        "5. Predict the accuracy for both train and validation data (5 points)\n",
        " If you are able to get very good accuracy, try and submit your submission in Kaggle. All the best !!\n",
        "\n",
        " Regards\n",
        "\n",
        "Program Office\n"
      ]
    },
    {
      "metadata": {
        "id": "o5QBgW4imk6Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load necessary libraries and functions"
      ]
    },
    {
      "metadata": {
        "id": "KA2y4WgYmkTh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "tf.set_random_seed(42)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-sliny0nVBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load dataset"
      ]
    },
    {
      "metadata": {
        "id": "LYfMjxj7PdZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3cb01f7e-d02c-4c3c-c6ee-858442320391"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9xFFDpspMqym",
        "colab_type": "code",
        "outputId": "4555b203-53a7-4464-8b8f-a205bcfcc8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mgdBKNbeWkqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "17II9V40Mq1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "project_path = '/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxK84K6kMq4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_path = project_path + 'train.zip'\n",
        "test_path = project_path + 'test.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YidortFldEQd",
        "colab_type": "code",
        "outputId": "a0aa0fec-b163-4b0a-d11c-191464f61bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "train_path"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification/train.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "lM93i7pzT0Wl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2R0zia9iT2Vu",
        "colab_type": "code",
        "outputId": "0a949197-3c09-49e7-9ca1-5f5b4b21a0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.zip', 'train.zip', 'train', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ZiOBBjV7Mq7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('train.zip', 'r') as f:\n",
        "  f.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rtvwpd4Nf3dO",
        "colab_type": "code",
        "outputId": "8bd97a93-4450-4203-d41a-cdc755622216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.zip', 'train.zip', 'train', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "C_nQU-RjfpGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('test.zip', 'r') as t:\n",
        "  t.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G7GyAzJTf43Q",
        "colab_type": "code",
        "outputId": "283431d0-f1d8-47f7-cb99-2d9c633f8717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.zip', 'train.zip', 'train', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Rl8010W0MrIA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wIudG6CBTtGu",
        "colab_type": "code",
        "outputId": "71a37d22-18fc-4c5d-a0f1-0e1d6069f215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir(project_path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv', 'test.zip', 'train.zip', 'train', 'test']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "NGs-d4CgT1x2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir(project_path + 'train/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGadWcayUUVe",
        "colab_type": "code",
        "outputId": "2a751c98-5016-4523-baf7-e97c0b37021a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fat Hen',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Cleavers',\n",
              " 'Black-grass',\n",
              " 'Sugar beet',\n",
              " 'Shepherds Purse',\n",
              " 'Charlock',\n",
              " 'Loose Silky-bent',\n",
              " 'Scentless Mayweed',\n",
              " 'Maize',\n",
              " 'Common Chickweed',\n",
              " 'Common wheat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "RwMMOe9_MrBy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "x_test=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pkNuRmxvUu_P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0RPr0IqUY1G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification/test')\n",
        "import cv2\n",
        "for i in os.listdir():\n",
        "    dummy = cv2.imread(i)\n",
        "    dummy = cv2.resize(dummy,(128,128))\n",
        "    x_test.append(dummy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-LOE4NEkwwOb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification/train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FP6KT1Iw44g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c92266e1-c531-4f03-bbd6-fb8e64046745"
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Fat Hen',\n",
              " 'Small-flowered Cranesbill',\n",
              " 'Cleavers',\n",
              " 'Black-grass',\n",
              " 'Sugar beet',\n",
              " 'Shepherds Purse',\n",
              " 'Charlock',\n",
              " 'Loose Silky-bent',\n",
              " 'Scentless Mayweed',\n",
              " 'Maize',\n",
              " 'Common Chickweed',\n",
              " 'Common wheat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "RleETohU7A8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "3b097421-fbd9-4914-b30f-2381f45c07dc"
      },
      "cell_type": "code",
      "source": [
        "for i in os.listdir():\n",
        "    print(i)\n",
        "    if (os.path.isdir(i)):\n",
        "            for j in os.listdir(i):\n",
        "                try:\n",
        "                    dummy = cv2.imread('/content/drive/My Drive/Colab Notebooks/Project 1/plant-seedlings-classification/train/' + i + \"/\" + j)\n",
        "                    dummy = cv2.resize(dummy,(128,128))\n",
        "                    x_train.append(dummy)\n",
        "                    y_train.append(i)\n",
        "                except Exception as e:\n",
        "                    print(e)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fat Hen\n",
            "Small-flowered Cranesbill\n",
            "Cleavers\n",
            "Black-grass\n",
            "Sugar beet\n",
            "Shepherds Purse\n",
            "Charlock\n",
            "Loose Silky-bent\n",
            "Scentless Mayweed\n",
            "Maize\n",
            "Common Chickweed\n",
            "Common wheat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CcZIxf1Jnozm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "a494ea75-cbaa-41b2-8225-5364a68b042f"
      },
      "cell_type": "code",
      "source": [
        "dum = pd.get_dummies(y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-bb233139e27c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         result = _get_dummies_1d(data, prefix, prefix_sep, dummy_na,\n\u001b[0;32m-> 1215\u001b[0;31m                                  sparse=sparse, drop_first=drop_first)\n\u001b[0m\u001b[1;32m   1216\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/reshape/reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[0;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first)\u001b[0m\n\u001b[1;32m   1220\u001b[0m                     sparse=False, drop_first=False):\n\u001b[1;32m   1221\u001b[0m     \u001b[0;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m     \u001b[0mcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_factorize_from_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_empty_Frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                 data = _sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 264\u001b[0;31m                                        raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   3273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3275\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data must be 1-dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3276\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3277\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NZJuTL6t7qA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoded_labels = dum\n",
        "y_train = dum"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rYPgEMPr7tut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np.array(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ME0eVSnD7wiG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScndDl3m7zvB",
        "colab_type": "code",
        "outputId": "4b53b7c4-4d8d-4a77-e9ec-fa00034f455c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "x_train[0].shape #number of images , x = 128 , y =128 , RGB = 3"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 128, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "T8PtO93tnYsX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide the data set into Train and validation data sets"
      ]
    },
    {
      "metadata": {
        "id": "yaJoxGJi7_AV",
        "colab_type": "code",
        "outputId": "bab494fc-ce54-4ea1-a035-4b5c0fde83f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train2, x_val, y_train2, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=2)\n",
        "print (len(x_train2))\n",
        "print (len(x_val))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3800\n",
            "950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RF5LjoUl8S3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train2 = x_train2.reshape(x_train2.shape[0],128,128,3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6P8tyyT8bmw",
        "colab_type": "code",
        "outputId": "abe6d0e0-5da7-42d1-e4ca-847cda7f3d5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5152
        }
      },
      "cell_type": "code",
      "source": [
        "x_train2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 54,  73,  94],\n",
              "         [ 54,  73,  94],\n",
              "         [ 54,  74,  94],\n",
              "         ...,\n",
              "         [124, 142, 149],\n",
              "         [127, 144, 151],\n",
              "         [129, 146, 153]],\n",
              "\n",
              "        [[ 51,  71,  92],\n",
              "         [ 52,  72,  92],\n",
              "         [ 52,  72,  92],\n",
              "         ...,\n",
              "         [123, 140, 148],\n",
              "         [126, 143, 151],\n",
              "         [128, 145, 152]],\n",
              "\n",
              "        [[ 48,  69,  90],\n",
              "         [ 48,  70,  90],\n",
              "         [ 49,  71,  91],\n",
              "         ...,\n",
              "         [122, 139, 148],\n",
              "         [125, 141, 150],\n",
              "         [127, 143, 152]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 26,  40,  57],\n",
              "         [ 24,  37,  53],\n",
              "         [ 19,  32,  47],\n",
              "         ...,\n",
              "         [107, 131, 142],\n",
              "         [107, 131, 141],\n",
              "         [107, 131, 140]],\n",
              "\n",
              "        [[ 19,  33,  50],\n",
              "         [ 14,  26,  44],\n",
              "         [  8,  17,  36],\n",
              "         ...,\n",
              "         [106, 129, 140],\n",
              "         [109, 132, 141],\n",
              "         [110, 133, 142]],\n",
              "\n",
              "        [[ 14,  27,  44],\n",
              "         [  8,  18,  37],\n",
              "         [  0,   6,  28],\n",
              "         ...,\n",
              "         [106, 128, 138],\n",
              "         [110, 132, 141],\n",
              "         [113, 135, 143]]],\n",
              "\n",
              "\n",
              "       [[[209, 201, 199],\n",
              "         [209, 200, 198],\n",
              "         [210, 202, 199],\n",
              "         ...,\n",
              "         [ 98,  88,  99],\n",
              "         [167, 162, 154],\n",
              "         [179, 172, 170]],\n",
              "\n",
              "        [[207, 199, 197],\n",
              "         [209, 201, 199],\n",
              "         [209, 201, 199],\n",
              "         ...,\n",
              "         [103,  94, 106],\n",
              "         [167, 162, 155],\n",
              "         [179, 172, 171]],\n",
              "\n",
              "        [[209, 201, 200],\n",
              "         [212, 204, 201],\n",
              "         [210, 201, 200],\n",
              "         ...,\n",
              "         [105,  98, 105],\n",
              "         [171, 165, 159],\n",
              "         [179, 172, 170]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 50,  67,  86],\n",
              "         [ 34,  50,  77],\n",
              "         [  8,  23,  52],\n",
              "         ...,\n",
              "         [ 56,  75,  92],\n",
              "         [ 64,  85, 104],\n",
              "         [ 65,  91, 108]],\n",
              "\n",
              "        [[ 45,  62,  84],\n",
              "         [ 38,  51,  77],\n",
              "         [ 35,  47,  67],\n",
              "         ...,\n",
              "         [ 55,  74,  94],\n",
              "         [ 62,  84, 104],\n",
              "         [ 69,  96, 112]],\n",
              "\n",
              "        [[ 40,  55,  74],\n",
              "         [ 45,  61,  76],\n",
              "         [ 42,  54,  71],\n",
              "         ...,\n",
              "         [ 56,  75,  94],\n",
              "         [ 59,  77,  98],\n",
              "         [ 74,  93, 110]]],\n",
              "\n",
              "\n",
              "       [[[ 32,  51,  71],\n",
              "         [ 25,  47,  67],\n",
              "         [ 21,  40,  65],\n",
              "         ...,\n",
              "         [ 55,  71,  84],\n",
              "         [ 46,  69,  94],\n",
              "         [ 45,  77,  99]],\n",
              "\n",
              "        [[ 32,  48,  73],\n",
              "         [ 27,  48,  70],\n",
              "         [ 23,  49,  80],\n",
              "         ...,\n",
              "         [ 63,  75,  89],\n",
              "         [ 43,  59,  84],\n",
              "         [ 42,  67,  90]],\n",
              "\n",
              "        [[ 29,  47,  70],\n",
              "         [ 25,  51,  75],\n",
              "         [ 19,  54,  91],\n",
              "         ...,\n",
              "         [ 67,  77,  94],\n",
              "         [ 48,  63,  84],\n",
              "         [ 27,  49,  77]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 52,  73,  93],\n",
              "         [ 50,  70,  89],\n",
              "         [ 49,  70,  89],\n",
              "         ...,\n",
              "         [ 32,  62,  84],\n",
              "         [ 34,  64,  89],\n",
              "         [ 36,  65, 100]],\n",
              "\n",
              "        [[ 72,  87, 102],\n",
              "         [ 72,  86, 100],\n",
              "         [ 53,  72,  87],\n",
              "         ...,\n",
              "         [ 38,  66,  90],\n",
              "         [ 35,  69,  91],\n",
              "         [ 40,  73,  97]],\n",
              "\n",
              "        [[ 83,  94, 108],\n",
              "         [ 76,  93, 107],\n",
              "         [ 42,  67,  86],\n",
              "         ...,\n",
              "         [ 37,  57,  79],\n",
              "         [ 36,  64,  84],\n",
              "         [ 31,  61,  82]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 42,  49,  64],\n",
              "         [ 45,  52,  66],\n",
              "         [ 45,  51,  64],\n",
              "         ...,\n",
              "         [ 24,  49,  62],\n",
              "         [ 22,  45,  59],\n",
              "         [ 17,  36,  53]],\n",
              "\n",
              "        [[ 42,  50,  63],\n",
              "         [ 43,  50,  63],\n",
              "         [ 45,  52,  65],\n",
              "         ...,\n",
              "         [ 22,  40,  60],\n",
              "         [ 22,  38,  59],\n",
              "         [ 20,  34,  55]],\n",
              "\n",
              "        [[ 43,  53,  65],\n",
              "         [ 42,  52,  64],\n",
              "         [ 45,  54,  66],\n",
              "         ...,\n",
              "         [ 21,  36,  58],\n",
              "         [ 22,  36,  58],\n",
              "         [ 17,  30,  52]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 45,  66,  85],\n",
              "         [ 47,  68,  87],\n",
              "         [ 51,  71,  90],\n",
              "         ...,\n",
              "         [ 62,  77,  95],\n",
              "         [ 60,  77,  94],\n",
              "         [ 55,  73,  89]],\n",
              "\n",
              "        [[ 45,  67,  89],\n",
              "         [ 47,  70,  90],\n",
              "         [ 51,  72,  92],\n",
              "         ...,\n",
              "         [ 52,  67,  87],\n",
              "         [ 46,  63,  82],\n",
              "         [ 40,  59,  76]],\n",
              "\n",
              "        [[ 49,  72,  94],\n",
              "         [ 45,  68,  90],\n",
              "         [ 43,  66,  88],\n",
              "         ...,\n",
              "         [ 43,  57,  78],\n",
              "         [ 35,  51,  73],\n",
              "         [ 35,  52,  71]]],\n",
              "\n",
              "\n",
              "       [[[ 84, 104, 125],\n",
              "         [ 75,  94, 116],\n",
              "         [ 72,  89, 111],\n",
              "         ...,\n",
              "         [ 94, 113, 125],\n",
              "         [ 99, 120, 130],\n",
              "         [ 92, 116, 126]],\n",
              "\n",
              "        [[ 75,  95, 118],\n",
              "         [ 73,  91, 114],\n",
              "         [ 72,  89, 111],\n",
              "         ...,\n",
              "         [ 82, 102, 115],\n",
              "         [ 91, 113, 123],\n",
              "         [ 89, 114, 124]],\n",
              "\n",
              "        [[ 70,  88, 113],\n",
              "         [ 70,  88, 111],\n",
              "         [ 69,  86, 109],\n",
              "         ...,\n",
              "         [ 71,  92, 108],\n",
              "         [ 85, 106, 118],\n",
              "         [ 86, 110, 121]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 47,  72, 101],\n",
              "         [ 47,  72, 101],\n",
              "         [ 48,  73, 103],\n",
              "         ...,\n",
              "         [ 48,  67,  82],\n",
              "         [ 48,  67,  83],\n",
              "         [ 40,  60,  76]],\n",
              "\n",
              "        [[ 45,  69,  98],\n",
              "         [ 46,  70,  98],\n",
              "         [ 45,  70,  98],\n",
              "         ...,\n",
              "         [ 46,  66,  80],\n",
              "         [ 48,  68,  82],\n",
              "         [ 45,  64,  79]],\n",
              "\n",
              "        [[ 40,  64,  91],\n",
              "         [ 45,  69,  96],\n",
              "         [ 49,  73,  99],\n",
              "         ...,\n",
              "         [ 45,  65,  79],\n",
              "         [ 48,  68,  81],\n",
              "         [ 48,  67,  81]]],\n",
              "\n",
              "\n",
              "       [[[ 50,  60,  76],\n",
              "         [ 52,  60,  77],\n",
              "         [ 65,  67,  74],\n",
              "         ...,\n",
              "         [ 56,  80, 101],\n",
              "         [ 46,  76, 101],\n",
              "         [ 58,  84, 103]],\n",
              "\n",
              "        [[ 36,  44,  81],\n",
              "         [ 30,  40,  74],\n",
              "         [ 59,  65,  81],\n",
              "         ...,\n",
              "         [ 60,  82, 105],\n",
              "         [ 59,  82, 103],\n",
              "         [ 61,  72,  91]],\n",
              "\n",
              "        [[ 21,  38,  75],\n",
              "         [ 45,  59,  96],\n",
              "         [ 44,  53,  97],\n",
              "         ...,\n",
              "         [ 79,  93, 105],\n",
              "         [ 41,  55,  94],\n",
              "         [ 38,  55, 104]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 37,  56,  75],\n",
              "         [ 29,  50,  67],\n",
              "         [ 34,  55,  80],\n",
              "         ...,\n",
              "         [ 43,  55,  74],\n",
              "         [ 41,  50,  66],\n",
              "         [ 42,  45,  59]],\n",
              "\n",
              "        [[ 37,  58,  78],\n",
              "         [ 29,  50,  71],\n",
              "         [ 26,  50,  75],\n",
              "         ...,\n",
              "         [ 56,  68,  84],\n",
              "         [ 43,  56,  71],\n",
              "         [ 31,  37,  56]],\n",
              "\n",
              "        [[ 57,  72,  85],\n",
              "         [ 33,  48,  69],\n",
              "         [ 22,  38,  62],\n",
              "         ...,\n",
              "         [ 52,  64,  81],\n",
              "         [ 53,  66,  80],\n",
              "         [ 61,  68,  87]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "uFk0C65Z8hUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_val = x_val.reshape(x_val.shape[0],128,128,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8D6EhEyd8jsO",
        "colab_type": "code",
        "outputId": "a3b4885a-17b4-46a5-8985-f50180eaf7d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5152
        }
      },
      "cell_type": "code",
      "source": [
        "x_val"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 77,  87, 102],\n",
              "         [ 83,  93, 107],\n",
              "         [ 80,  90, 104],\n",
              "         ...,\n",
              "         [ 39,  50,  75],\n",
              "         [ 42,  53,  76],\n",
              "         [ 44,  54,  77]],\n",
              "\n",
              "        [[ 75,  84, 100],\n",
              "         [ 78,  88, 103],\n",
              "         [ 78,  88, 102],\n",
              "         ...,\n",
              "         [ 38,  50,  76],\n",
              "         [ 41,  53,  77],\n",
              "         [ 43,  55,  78]],\n",
              "\n",
              "        [[ 69,  78,  94],\n",
              "         [ 73,  82,  98],\n",
              "         [ 73,  83,  98],\n",
              "         ...,\n",
              "         [ 39,  53,  78],\n",
              "         [ 40,  52,  77],\n",
              "         [ 42,  54,  78]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 61,  77,  89],\n",
              "         [ 59,  76,  87],\n",
              "         [ 57,  74,  87],\n",
              "         ...,\n",
              "         [ 96, 110, 115],\n",
              "         [ 93, 107, 112],\n",
              "         [ 92, 106, 112]],\n",
              "\n",
              "        [[ 58,  75,  86],\n",
              "         [ 57,  75,  86],\n",
              "         [ 54,  72,  84],\n",
              "         ...,\n",
              "         [ 95, 108, 113],\n",
              "         [ 95, 108, 113],\n",
              "         [ 97, 110, 115]],\n",
              "\n",
              "        [[ 52,  70,  82],\n",
              "         [ 51,  70,  81],\n",
              "         [ 49,  68,  79],\n",
              "         ...,\n",
              "         [ 88, 103, 108],\n",
              "         [ 93, 107, 111],\n",
              "         [ 97, 110, 114]]],\n",
              "\n",
              "\n",
              "       [[[ 74,  69,  81],\n",
              "         [ 82,  71,  83],\n",
              "         [ 94,  83,  93],\n",
              "         ...,\n",
              "         [ 51,  61,  71],\n",
              "         [ 47,  55,  63],\n",
              "         [ 37,  40,  50]],\n",
              "\n",
              "        [[ 72,  66,  72],\n",
              "         [ 84,  72,  79],\n",
              "         [117, 110, 109],\n",
              "         ...,\n",
              "         [ 53,  62,  68],\n",
              "         [ 45,  51,  61],\n",
              "         [ 34,  35,  50]],\n",
              "\n",
              "        [[ 82,  70,  79],\n",
              "         [115, 106, 104],\n",
              "         [152, 148, 138],\n",
              "         ...,\n",
              "         [ 53,  62,  68],\n",
              "         [ 42,  46,  56],\n",
              "         [ 35,  34,  47]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 67,  62,  65],\n",
              "         [ 70,  67,  69],\n",
              "         [ 67,  66,  68],\n",
              "         ...,\n",
              "         [ 40,  51,  66],\n",
              "         [ 42,  52,  67],\n",
              "         [ 45,  56,  69]],\n",
              "\n",
              "        [[ 70,  66,  66],\n",
              "         [ 70,  65,  67],\n",
              "         [ 66,  61,  65],\n",
              "         ...,\n",
              "         [ 43,  55,  73],\n",
              "         [ 43,  52,  68],\n",
              "         [ 39,  49,  63]],\n",
              "\n",
              "        [[ 68,  64,  65],\n",
              "         [ 69,  65,  65],\n",
              "         [ 60,  54,  58],\n",
              "         ...,\n",
              "         [ 39,  53,  72],\n",
              "         [ 35,  43,  63],\n",
              "         [ 40,  48,  62]]],\n",
              "\n",
              "\n",
              "       [[[ 66,  89, 105],\n",
              "         [ 76, 102, 117],\n",
              "         [ 79, 109, 126],\n",
              "         ...,\n",
              "         [ 57,  90, 115],\n",
              "         [ 67,  93, 119],\n",
              "         [ 71,  95, 115]],\n",
              "\n",
              "        [[ 65,  89, 105],\n",
              "         [ 87, 112, 122],\n",
              "         [ 82, 115, 128],\n",
              "         ...,\n",
              "         [ 62,  90, 116],\n",
              "         [ 61,  87, 109],\n",
              "         [ 63,  88, 108]],\n",
              "\n",
              "        [[ 64,  87, 101],\n",
              "         [ 82, 107, 117],\n",
              "         [ 79, 112, 124],\n",
              "         ...,\n",
              "         [ 62,  89, 112],\n",
              "         [ 62,  87, 108],\n",
              "         [ 57,  82, 103]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 31,  49,  73],\n",
              "         [ 34,  49,  73],\n",
              "         [ 32,  43,  68],\n",
              "         ...,\n",
              "         [103, 118, 128],\n",
              "         [111, 124, 129],\n",
              "         [ 94, 107, 119]],\n",
              "\n",
              "        [[ 23,  28,  57],\n",
              "         [ 37,  45,  71],\n",
              "         [ 39,  50,  74],\n",
              "         ...,\n",
              "         [114, 125, 136],\n",
              "         [113, 126, 134],\n",
              "         [ 99, 112, 122]],\n",
              "\n",
              "        [[ 67,  78, 100],\n",
              "         [107, 125, 131],\n",
              "         [117, 136, 143],\n",
              "         ...,\n",
              "         [119, 134, 140],\n",
              "         [112, 128, 135],\n",
              "         [ 89, 101, 114]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[205, 195, 190],\n",
              "         [204, 193, 191],\n",
              "         [202, 193, 189],\n",
              "         ...,\n",
              "         [179, 172, 165],\n",
              "         [192, 181, 178],\n",
              "         [192, 182, 180]],\n",
              "\n",
              "        [[204, 194, 190],\n",
              "         [204, 192, 190],\n",
              "         [203, 193, 190],\n",
              "         ...,\n",
              "         [179, 172, 168],\n",
              "         [192, 183, 179],\n",
              "         [192, 185, 181]],\n",
              "\n",
              "        [[188, 181, 179],\n",
              "         [193, 186, 185],\n",
              "         [199, 190, 187],\n",
              "         ...,\n",
              "         [190, 184, 180],\n",
              "         [200, 192, 190],\n",
              "         [197, 189, 183]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 48,  60,  76],\n",
              "         [ 56,  66,  80],\n",
              "         [ 52,  66,  79],\n",
              "         ...,\n",
              "         [ 57,  72,  92],\n",
              "         [ 55,  71,  94],\n",
              "         [ 48,  63,  83]],\n",
              "\n",
              "        [[ 50,  62,  79],\n",
              "         [ 35,  43,  65],\n",
              "         [ 30,  42,  61],\n",
              "         ...,\n",
              "         [ 51,  71,  86],\n",
              "         [ 53,  69,  90],\n",
              "         [ 53,  66,  88]],\n",
              "\n",
              "        [[ 79,  86,  92],\n",
              "         [ 36,  43,  62],\n",
              "         [ 37,  51,  73],\n",
              "         ...,\n",
              "         [ 52,  67,  84],\n",
              "         [ 51,  69,  91],\n",
              "         [ 50,  70,  92]]],\n",
              "\n",
              "\n",
              "       [[[195, 195, 192],\n",
              "         [189, 187, 185],\n",
              "         [184, 183, 181],\n",
              "         ...,\n",
              "         [ 86, 102, 117],\n",
              "         [ 66,  82,  93],\n",
              "         [ 67,  81,  93]],\n",
              "\n",
              "        [[194, 192, 189],\n",
              "         [193, 189, 187],\n",
              "         [188, 187, 185],\n",
              "         ...,\n",
              "         [ 72,  90, 102],\n",
              "         [ 51,  63,  77],\n",
              "         [ 50,  63,  77]],\n",
              "\n",
              "        [[194, 191, 189],\n",
              "         [192, 191, 189],\n",
              "         [186, 186, 186],\n",
              "         ...,\n",
              "         [ 48,  54,  64],\n",
              "         [ 49,  58,  67],\n",
              "         [ 43,  48,  62]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[187, 187, 186],\n",
              "         [185, 183, 179],\n",
              "         [180, 180, 178],\n",
              "         ...,\n",
              "         [ 31,  33,  43],\n",
              "         [ 21,  25,  39],\n",
              "         [ 33,  45,  62]],\n",
              "\n",
              "        [[189, 187, 186],\n",
              "         [185, 185, 181],\n",
              "         [181, 179, 178],\n",
              "         ...,\n",
              "         [ 23,  27,  42],\n",
              "         [ 21,  26,  40],\n",
              "         [ 13,  20,  35]],\n",
              "\n",
              "        [[191, 188, 188],\n",
              "         [184, 185, 183],\n",
              "         [187, 185, 181],\n",
              "         ...,\n",
              "         [ 44,  57,  71],\n",
              "         [ 34,  44,  57],\n",
              "         [ 35,  46,  53]]],\n",
              "\n",
              "\n",
              "       [[[141, 144, 142],\n",
              "         [141, 144, 142],\n",
              "         [141, 141, 141],\n",
              "         ...,\n",
              "         [ 85, 103, 117],\n",
              "         [ 46,  63,  86],\n",
              "         [ 59,  83, 106]],\n",
              "\n",
              "        [[142, 144, 141],\n",
              "         [140, 141, 140],\n",
              "         [142, 143, 142],\n",
              "         ...,\n",
              "         [ 87, 105, 118],\n",
              "         [ 88, 103, 119],\n",
              "         [ 52,  77, 100]],\n",
              "\n",
              "        [[142, 144, 142],\n",
              "         [142, 144, 145],\n",
              "         [142, 142, 142],\n",
              "         ...,\n",
              "         [ 89, 104, 118],\n",
              "         [ 76,  93, 112],\n",
              "         [ 55,  79, 100]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[140, 142, 141],\n",
              "         [142, 143, 141],\n",
              "         [139, 142, 139],\n",
              "         ...,\n",
              "         [ 36,  70, 103],\n",
              "         [ 29,  59,  90],\n",
              "         [ 61,  91, 112]],\n",
              "\n",
              "        [[142, 143, 142],\n",
              "         [142, 143, 138],\n",
              "         [142, 143, 141],\n",
              "         ...,\n",
              "         [ 41,  72, 106],\n",
              "         [ 39,  59,  83],\n",
              "         [ 67,  74,  82]],\n",
              "\n",
              "        [[139, 143, 140],\n",
              "         [139, 142, 140],\n",
              "         [141, 142, 140],\n",
              "         ...,\n",
              "         [ 46,  63,  81],\n",
              "         [ 55,  65,  77],\n",
              "         [ 52,  58,  69]]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "6YgoikgI8ni9",
        "colab_type": "code",
        "outputId": "4f299360-0de4-4cb9-e700-6366a5aac862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print (x_train2.shape)\n",
        "print (x_val.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3800, 128, 128, 3)\n",
            "(950, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6oY7lW1E8rLe",
        "colab_type": "code",
        "outputId": "2a867e89-4bef-43e9-bbc0-f14e0a71ad98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(y_train2.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3800, 12)\n",
            "(950, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hLqDxNv5na2_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize & build the model (10 points)"
      ]
    },
    {
      "metadata": {
        "id": "XUdYrbe_8wR3",
        "colab_type": "code",
        "outputId": "2744335a-78c9-427c-a716-23cf6dba9c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "REnYQdTcnpZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xM8luCr185W1",
        "colab_type": "code",
        "outputId": "c95e89ae-6af1-4294-be2d-ce0d8b3a0267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape = (128,128,3)))\n",
        "model.add(Convolution2D(32, (3,3), activation ='relu', input_shape = (128, 128, 3))) \n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Convolution2D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Convolution2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Convolution2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Flatten()) \n",
        "\n",
        "# fully connected layer\n",
        "model.add(Dense(units=128,activation = 'relu'))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(units = 32, activation = 'relu'))\n",
        "#model.add(Dropout(0.3))\n",
        "model.add(Dense(units = 12, activation = 'softmax')) \n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6dQdzgsjnelI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Optimize the model (5 points)"
      ]
    },
    {
      "metadata": {
        "id": "CNdxnUtWnqEg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = adam(lr=0.001)\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EuJWeIB1nqHw",
        "colab_type": "code",
        "outputId": "47201e2d-40b8-4856-e0d7-b6cd3ee80674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 128, 128, 3)       12        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 63, 63, 64)        32832     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 31, 31, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       65664     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 12)                396       \n",
            "=================================================================\n",
            "Total params: 986,936\n",
            "Trainable params: 986,930\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S7yjxv28niBw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict the accuracy for both train and validation data (5 points)"
      ]
    },
    {
      "metadata": {
        "id": "aZZ3g2osnnof",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "01c815e1-1907-4731-fa85-8bf0e89aee40"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "nb_epochs = 10\n",
        "history = model.fit(x_train,y_train,\n",
        "                    epochs=20, \n",
        "                    validation_data=(x_val,y_val),\n",
        "                    verbose = 1,\n",
        "                    initial_epoch=0)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 4750 samples, validate on 950 samples\n",
            "Epoch 1/20\n",
            "4750/4750 [==============================] - 292s 61ms/step - loss: 1.8802 - acc: 0.3396 - val_loss: 1.3601 - val_acc: 0.5084\n",
            "Epoch 2/20\n",
            "4750/4750 [==============================] - 290s 61ms/step - loss: 1.1038 - acc: 0.6189 - val_loss: 0.8539 - val_acc: 0.7042\n",
            "Epoch 3/20\n",
            "4750/4750 [==============================] - 291s 61ms/step - loss: 0.7980 - acc: 0.7246 - val_loss: 0.6005 - val_acc: 0.8011\n",
            "Epoch 4/20\n",
            "4750/4750 [==============================] - 288s 61ms/step - loss: 0.6097 - acc: 0.7920 - val_loss: 0.6023 - val_acc: 0.8011\n",
            "Epoch 5/20\n",
            "4750/4750 [==============================] - 288s 61ms/step - loss: 0.4841 - acc: 0.8335 - val_loss: 0.3925 - val_acc: 0.8558\n",
            "Epoch 6/20\n",
            "4750/4750 [==============================] - 289s 61ms/step - loss: 0.3610 - acc: 0.8712 - val_loss: 0.2024 - val_acc: 0.9253\n",
            "Epoch 7/20\n",
            "4750/4750 [==============================] - 289s 61ms/step - loss: 0.3000 - acc: 0.8918 - val_loss: 0.1930 - val_acc: 0.9232\n",
            "Epoch 8/20\n",
            "4750/4750 [==============================] - 287s 61ms/step - loss: 0.2459 - acc: 0.9084 - val_loss: 0.1727 - val_acc: 0.9326\n",
            "Epoch 9/20\n",
            "4750/4750 [==============================] - 288s 61ms/step - loss: 0.2121 - acc: 0.9179 - val_loss: 0.1777 - val_acc: 0.9347\n",
            "Epoch 10/20\n",
            "4750/4750 [==============================] - 287s 60ms/step - loss: 0.2189 - acc: 0.9181 - val_loss: 0.1161 - val_acc: 0.9547\n",
            "Epoch 11/20\n",
            "4750/4750 [==============================] - 288s 61ms/step - loss: 0.1736 - acc: 0.9331 - val_loss: 0.1124 - val_acc: 0.9547\n",
            "Epoch 12/20\n",
            "4750/4750 [==============================] - 286s 60ms/step - loss: 0.1714 - acc: 0.9358 - val_loss: 0.1681 - val_acc: 0.9137\n",
            "Epoch 13/20\n",
            "4750/4750 [==============================] - 287s 60ms/step - loss: 0.1116 - acc: 0.9583 - val_loss: 0.0728 - val_acc: 0.9726\n",
            "Epoch 14/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.0941 - acc: 0.9653 - val_loss: 0.0688 - val_acc: 0.9758\n",
            "Epoch 15/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.0902 - acc: 0.9697 - val_loss: 0.0618 - val_acc: 0.9716\n",
            "Epoch 16/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.1251 - acc: 0.9543 - val_loss: 0.0641 - val_acc: 0.9758\n",
            "Epoch 17/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.0664 - acc: 0.9794 - val_loss: 0.0666 - val_acc: 0.9747\n",
            "Epoch 18/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.1254 - acc: 0.9577 - val_loss: 0.0388 - val_acc: 0.9905\n",
            "Epoch 19/20\n",
            "4750/4750 [==============================] - 284s 60ms/step - loss: 0.0910 - acc: 0.9712 - val_loss: 0.0412 - val_acc: 0.9842\n",
            "Epoch 20/20\n",
            "4750/4750 [==============================] - 282s 59ms/step - loss: 0.0400 - acc: 0.9855 - val_loss: 0.0416 - val_acc: 0.9916\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}